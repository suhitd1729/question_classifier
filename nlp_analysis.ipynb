{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : To create a classifier that can identify whether or not a provided series of words is a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Two approaches have been followed : \n",
    "\n",
    "1) The first approach is more naive. It just checks for certain words such as how , where, what , when etc. \n",
    "(will refer to these as q_words from here on) in the text provided. \n",
    "Normally, I would have only checked if any of the sentences provided begins with one of the q_words, but then,\n",
    "I would miss out on sentences which might be a question where the q_words occur in the middle. \n",
    "Since my aim is to build an adequate Question identifier model , I would rather have a few False Positives than miss \n",
    "out on a Inquiry statement that might be relevant.\n",
    "The analogy is similar to Spam Filtering. We would prefer having a Spam labelled as Non-Spam than have an important \n",
    "email labelled as a Spam and miss out on it. \n",
    "\n",
    "2) Using nps_chat corpus which comprises of sample chats and their corresponding dialogue act types. \n",
    "There are 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\" etc. The nps_chat corpus can be obtained \n",
    "from the nltk library.\n",
    "Amongst the dialogue act types, the ones that are of type \"ynQuestion\" and \"whQuestion\",\n",
    "are classified as 1 and the rest as 0. This would serve as a reference source (training data)\n",
    "Using this training data , a Naive Bayes model is built which is used to test on the sample data provided. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference : https://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\suhit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\nps_chat.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\suhit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwords = [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\", \"can\", \"does\", \"do\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test-inputs.txt', encoding='utf8')\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    for q in qwords:\n",
    "        if q in line.lower():\n",
    "            qexist = True\n",
    "            break\n",
    "        else:\n",
    "            qexist = False\n",
    "    if qexist:\n",
    "        outcome.append(1)\n",
    "    else:\n",
    "        outcome.append(0)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename ,mode = 'w') as outfile:\n",
    "    for o in outcome:\n",
    "        outfile.write(\"%s\\n\" % o)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "         features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist = []\n",
    "classlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature , dt in featuresets:\n",
    "    featurelist.append(feature)\n",
    "    classlist.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two types of Question : whQuestion and ynQuestion\n",
    "classlist = [1 if 'Question' in classval  else 0 for classval in classlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list(zip(featurelist,classlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('test-inputs.txt', encoding='utf8')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    test_set.append(dialogue_act_features(line))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier.classify_many(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output_nltk.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename ,mode = 'w') as outfile:\n",
    "    for o in output:\n",
    "        outfile.write(\"%s\\n\" % o)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
